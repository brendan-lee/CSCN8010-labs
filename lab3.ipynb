{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Obtain the dataset\n",
    "\n",
    "The dataset (https://www.kaggle.com/datasets/biaiscience/dogs-vs-cats, with Open Data license) contains images of dogs and cats, divided into training (1000 dogs, 1000 cats), validation (500 dogs, 500 cats), and test sets (1000 dogs, 1000 cats). Each image has a resolution of 180Ã—180.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import pathlib\n",
    "\n",
    "dataset_dir = pathlib.Path(\"./data/kaggle_dogs_vs_cats_small\")\n",
    "\n",
    "# load the dataset\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    dataset_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    dataset_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    dataset_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "\n",
    "# Calculate the class distribution for each subset\n",
    "def get_class_counts(dataset):\n",
    "    counts = {}\n",
    "    for _, labels in dataset:\n",
    "        unique, counts_unique = np.unique(labels, return_counts=True)\n",
    "        for u, c in zip(unique, counts_unique):\n",
    "            class_name = class_names[int(u)]\n",
    "            counts[class_name] = counts.get(class_name, 0) + c\n",
    "    return counts\n",
    "\n",
    "\n",
    "train_counts = get_class_counts(train_dataset)\n",
    "validation_counts = get_class_counts(validation_dataset)\n",
    "test_counts = get_class_counts(test_dataset)\n",
    "\n",
    "counts_df = pd.DataFrame(\n",
    "    {\"Train\": train_counts, \"Validation\": validation_counts, \"Test\": test_counts},\n",
    "    index=class_names,\n",
    ")\n",
    "\n",
    "print(\"Class distribution for each subset:\")\n",
    "counts_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot the class distribution\n",
    "plt.figure(figsize=(6, 6))\n",
    "counts_df.plot(kind=\"bar\")\n",
    "plt.title(\"Class distribution\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Display sample images\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[int(labels[i])])\n",
    "        plt.axis(\"off\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Image size and color channels\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get the first image from the training dataset\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Image size: {images.shape[1:3]}\")\n",
    "    print(f\"Image color channels: {images.shape[3]}\")\n",
    "    break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training vanilla CNN model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a vanilla CNN model with data augmentation and dropout.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_vanilla_cnn_model():\n",
    "    inputs = keras.Input(shape=(180, 180, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "vanilla_cnn_model = create_vanilla_cnn_model()\n",
    "vanilla_cnn_model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the vanilla CNN model."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "vanilla_callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models/vanilla_cnn_model.h5\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "    )\n",
    "]\n",
    "\n",
    "vanilla_history = vanilla_cnn_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=vanilla_callbacks,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_history(history):\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs_range = range(1, len(accuracy) + 1)\n",
    "\n",
    "    # accuracy\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs_range, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    # loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs_range, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(vanilla_history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning VGG16 model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the VGG16 model with pre-trained ImageNet weights, remove the top layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "conv_base.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new model using VGG16 as the base, freezing all layers except the top four layers, and add a custom head for fine-tuning. Additionally, use data augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_finetuned_model(conv_base):\n",
    "    # Freeze all layers until the fourth from the last.\n",
    "    conv_base.trainable = True\n",
    "    for layer in conv_base.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=(180, 180, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = keras.applications.vgg16.preprocess_input(x)\n",
    "    x = conv_base(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "finetuned_model = create_finetuned_model(conv_base)\n",
    "finetuned_model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the fine-tuned VGG16 model."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "finetuned_callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models/finetuned_vgg16_model.h5\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "    )\n",
    "]\n",
    "\n",
    "finetuned_history = finetuned_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=finetuned_callbacks,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_history(finetuned_history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the models\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define functions to evaluate the models and display the results."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_predictions(model, dataset):\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    y_pred_bin_all = []\n",
    "\n",
    "    for images, y_true in dataset:\n",
    "        y_pred = model.predict(images)\n",
    "        y_pred_bin = (y_pred > 0.5)\n",
    "\n",
    "        y_true_all.extend(y_true)\n",
    "        y_pred_all.extend(y_pred)\n",
    "        y_pred_bin_all.extend(y_pred_bin)\n",
    "\n",
    "    return (np.array(y_true_all).flatten().astype(int),\n",
    "            np.array(y_pred_all).flatten(),\n",
    "            np.array(y_pred_bin_all).flatten().astype(int))\n",
    "\n",
    "\n",
    "def calc_confusion_matrix(y_true, y_pred_bin):\n",
    "    cm = tf.math.confusion_matrix(y_true, y_pred_bin)\n",
    "    TP = cm[1][1]\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, marker=\".\", label=f\"AUC: {pr_auc:.3f}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_model(model_path, dataset):\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    y_true, y_pred, y_pred_bin = get_predictions(model, dataset)\n",
    "    TP, TN, FP, FN = calc_confusion_matrix(y_true, y_pred_bin)\n",
    "\n",
    "    result = f\"\\n{classification_report(y_true, y_pred_bin, target_names=class_names)}\\n\"\n",
    "\n",
    "    result += f\"\\nConfusion matrix:\\n\"\n",
    "    result += f\"{'-' * 25}\\n\"\n",
    "    result += f\"| TP: {TP:5} | FP: {FP:5} |\\n\"\n",
    "    result += f\"{'-' * 25}\\n\"\n",
    "    result += f\"| FN: {FN:5} | TN: {TN:5} |\\n\"\n",
    "    result += f\"{'-' * 25}\"\n",
    "\n",
    "    return result, y_true, y_pred, y_pred_bin\n",
    "\n",
    "\n",
    "def show_misclassified_images(y_true, y_pred_bin, dataset, max_num=5):\n",
    "    errors = np.where(y_true != y_pred_bin)[0]\n",
    "\n",
    "    max_cols = 5\n",
    "    num_images = min(len(errors), max_num)\n",
    "    rows = (num_images + max_cols - 1) // max_cols\n",
    "    \n",
    "    selected_errors = np.random.choice(errors, num_images, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, max_cols, figsize=(15, 4 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(selected_errors):\n",
    "        image, label = list(dataset.unbatch().as_numpy_iterator())[idx]\n",
    "        prediction = class_names[y_pred_bin[idx]]\n",
    "\n",
    "        axes[i].imshow(image.astype(\"uint8\"))\n",
    "        axes[i].set_title(f\"True: {class_names[int(label)]}     Pred: {prediction}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Hide the remaining axes\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Misclassified images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1 Vanilla CNN model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the vanilla CNN model\n",
    "(vanilla_report,\n",
    " y_true_vanilla,\n",
    " y_pred_vanilla,\n",
    " y_pred_bin_vanilla) = evaluate_model(\"./models/vanilla_cnn_model.h5\", test_dataset)\n",
    "\n",
    "print(f\"\\n\\nVanilla CNN model:\\n{vanilla_report}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#ã€€Show misclassified images\n",
    "show_misclassified_images(y_true_vanilla, y_pred_bin_vanilla, test_dataset, 10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Fine-tuned VGG16 model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the fine-tuned VGG 16 model\n",
    "(finetuned_report,\n",
    " y_true_finetuned,\n",
    " y_pred_finetuned,\n",
    " y_pred_bin_finetuned) = evaluate_model(\"./models/finetuned_vgg16_model.h5\", test_dataset)\n",
    "\n",
    "print(f\"\\n\\nFine-tuned VGG16 model:\\n{finetuned_report}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show misclassified images\n",
    "show_misclassified_images(y_true_finetuned, y_pred_bin_finetuned, test_dataset, 10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundations_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
